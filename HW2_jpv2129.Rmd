---
title: "Homework 2"
author: "Jake Vettoretti"
date: "2025-09-26"
output: github_document
---

```{r setup, echo=FALSE, message=FALSE}
library(tidyverse) #installing necessary libraries
library(readr)
library(readxl)
library(lubridate)
library(knitr)
```

## Problem 1

Installing and cleaning pols data.

```{r}
pols_df = read_csv("data/pols-month.csv") |> #Clean pols.csv data
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = TRUE) |> 
  mutate(
    month = month.name[as.numeric(month)],
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem",
      TRUE ~ NA_character_
    )
  ) |> 
  select(-prez_dem, -prez_gop, -day) |> 
  arrange(year, month)

pols_df
```

Installing and cleaning snp data.

```{r}
snp_df = read_csv("data/snp.csv") |>  # Clean snp.csv data
  janitor::clean_names() |>
  mutate(
    date = as.Date(date, format = "%m/%d/%y"),
    year = as.integer(ifelse(
      format(date, "%y") <= "68", 
      paste0("20", format(date, "%y")),
      paste0("19", format(date, "%y"))
    )),
    month = month.name[as.integer(format(date, "%m"))]
  ) |>
  select(year, month, close) |>
  arrange(year, month)

snp_df
```

Preparing datasets for merge.

```{r}
unemployment_df = read_csv("data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = jan:dec,
    names_to = "month_abbr",
    values_to = "unemployment_rate"
  ) |> 
  # Convert abbreviations using month.name and month.abb constants
  mutate(month = month.name[match(month_abbr, tolower(month.abb))]) |> 
  select(-month_abbr) |> 
  rename(year = year) |> 
  arrange(year, month)
```

Merging the data sets

```{r}
merged_data = pols_df |> #merging pols and snp to prepare for merge into unemployment
  left_join(snp_df, by = c("year", "month"))

final_data = merged_data |>  # Step 2: Merge unemployment into the result  
  left_join(unemployment_df, by = c("year", "month"))

final_data
```

Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset 
(e.g. give the dimension, range of years, and names of key variables):

## Problem 2

Importing and cleaning the Mr. Trash Wheel Data

```{r}
# Mr. Trash Wheel
mr_trash_wheel = read_excel("data/trashwheeldatanew.xlsx", 
  sheet = "Mr. Trash Wheel", skip = 1, na = c("NA", ".", "")) %>%  # Skip the first row (metadata/header),
  janitor:: clean_names() |>  # Clean column names and remove rows that don't have dumpster data (NA in dumpster column)
  filter(!is.na(dumpster))|>
  mutate(sports_balls = as.integer(round(sports_balls))) |> 
  select(dumpster:homes_powered)   # Select only the relevant columns with dumpster-specific data
mr_trash_wheel

# Professor Trash Wheel - same process with consistent data types
professor_trash_wheel = read_excel("data/trashwheeldatanew.xlsx", 
  sheet = "Professor Trash Wheel", skip = 1, na = c("NA", ".", "")) %>%  
  janitor::clean_names() |>  
  filter(!is.na(dumpster))|>
  # Ensure consistent data types
  mutate(
    year = as.character(year)  # Convert to character to match Mr. Trash Wheel
  ) |>
  select(dumpster:homes_powered)

# Gwynnda Trash Wheel - same process with consistent data types
gwynns_trash_wheel = read_excel("data/trashwheeldatanew.xlsx", 
  sheet = "Gwynns Falls Trash Wheel", skip = 1, na = c("NA", ".", "")) %>%  
  janitor::clean_names() |>  
  filter(!is.na(dumpster))|>
  # Ensure consistent data types
  mutate(
    year = as.character(year)  # Convert to character to match Mr. Trash Wheel
  ) |>
  select(dumpster:homes_powered)

# Add identifier variable to each dataset
mr_trash_wheel = mr_trash_wheel |> 
  mutate(trash_wheel = "Mr. Trash Wheel")

professor_trash_wheel = professor_trash_wheel |> 
  mutate(trash_wheel = "Professor Trash Wheel")

gwynns_trash_wheel = gwynns_trash_wheel |> 
  mutate(trash_wheel = "Gwynns Falls Trash Wheel")

all_trash_wheels = mr_trash_wheel |> 
  full_join(professor_trash_wheel) |> 
  full_join(gwynns_trash_wheel) |> 
  select(trash_wheel, everything())  # Move identifier to first column

# View the combined tidy dataset
all_trash_wheels
view(all_trash_wheels)

#Calculations requested for trash tons total and cigarette butts for June 2022
professor_total_weight <- all_trash_wheels |> 
  filter(trash_wheel == "Professor Trash Wheel") |> 
  summarise(total_weight_tons = sum(weight_tons, na.rm = TRUE))

gwynns_june_2022_butts <- all_trash_wheels |> 
  filter(trash_wheel == "Gwynns Falls Trash Wheel",
         year == "2022",
         month == "June") |> 
  summarise(total_cigarette_butts = sum(cigarette_butts, na.rm = TRUE))

# Display results
cat("Total weight of trash collected by Professor Trash Wheel:\n")
print(professor_total_weight)

cat("\nTotal number of cigarette butts collected by Gwynns in June 2022:\n")
print(gwynns_june_2022_butts)
```

Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. 
For available data, what was the total weight of trash collected by Professor Trash Wheel? 
  282 tons.
What was the total number of cigarette butts collected by Gwynnda in June of 2022?
  18,120 cigarette butts.

## Problem 3
```{r}
zipcodes_df = read_csv("data/zillowdata/zipcodes.csv", na = c("NA", ".", "")) |>  
  janitor::clean_names() |> 
  select(
    -file_date,
    -county
  )

view(zipcodes_df)

zori_df = read_csv("data/zillowdata/zipzori.csv", na = c("NA", ".", "")) |>  
  janitor::clean_names() |> 
  pivot_longer(
    cols = starts_with("x20"),
    names_to = "date",
    values_to = "zillow_value"
  ) |> 
  mutate(
    date = format(ymd(gsub("x", "", date)), "%m/%d/%y")
  ) |> 
  select(
    zip_code = region_name,
    county = county_name,
    date,
    zillow_value,
    -region_id, -size_rank, -region_type, -state_name
  )

tidy_df <- zori_df |> 
  left_join(zipcodes_df, by = "zip_code") 
```

```{r}
tidy_df <- tidy_df |> #Adding borough variable to tidy_df
  mutate(
    borough = case_when(
      county == "New York County" ~ "Manhattan",
      county == "Kings County" ~ "Brooklyn", 
      county == "Queens County" ~ "Queens",
      county == "Bronx County" ~ "Bronx",
      county == "Richmond County" ~ "Staten Island",
      # Handle variations in county naming
      str_detect(tolower(county), "new york") ~ "Manhattan",
      str_detect(tolower(county), "kings") ~ "Brooklyn",
      str_detect(tolower(county), "queens") ~ "Queens", 
      str_detect(tolower(county), "bronx") ~ "Bronx",
      str_detect(tolower(county), "richmond") ~ "Staten Island",
      TRUE ~ "Other"  # For non-NYC counties
    )
  )
tidy_df <- tidy_df |>  # Create the borough column from county
  mutate(
    borough = case_when(
      str_detect(county, "New York") ~ "Manhattan",
      str_detect(county, "Kings") ~ "Brooklyn",
      str_detect(county, "Queens") ~ "Queens",
      str_detect(county, "Bronx") ~ "Bronx",
      str_detect(county, "Richmond") ~ "Staten Island",
      TRUE ~ "Other NYC Area"
    )
  )
view(tidy_df)
nrow(tidy_df) #Finding number of observations
dim(tidy_df)
```
Description of tidy_df: There are a total of 17, 516 observations. There are 43 unique neighborhoods. There are 149 unique zip codes. 149

```{r}
# Check unique ZIP codes and neighborhoods
cat("Number of unique ZIP codes:", n_distinct(tidy_df$zip_code), "\n")
cat("Number of unique neighborhoods:", n_distinct(tidy_df$neighborhood), "\n")

# Find ZIP codes in zipcodes_df but not in zori_df
missing_zips <- zipcodes_df %>%
  anti_join(zori_df, by = "zip_code") %>%
  select(zip_code) %>%
  distinct()

cat("Number of ZIP codes in ZIP code dataset but not in Zillow dataset:", nrow(missing_zips), "\n")
```
There are 171 ZIP codes from the ZIP code dataset that do not appear in the Zillow dataset. This is possibly because of:
```{r}
#Creating table to find 10 biggest price drops with county and neighborhood
top_drops <- tidy_df %>%
  mutate(borough = case_when(
    str_detect(county, "New York") ~ "Manhattan",
    str_detect(county, "Kings") ~ "Brooklyn",
    str_detect(county, "Queens") ~ "Queens",
    str_detect(county, "Bronx") ~ "Bronx", 
    str_detect(county, "Richmond") ~ "Staten Island",
    TRUE ~ "Other NYC Area"
  )) %>%
  filter(date %in% c("01/31/20", "01/31/21")) %>%
  group_by(zip_code) %>% filter(n() == 2) %>%
  pivot_wider(names_from = date, values_from = zillow_value) %>%
  mutate(
    price_drop = `01/31/21` - `01/31/20`,
    percent_drop = ((`01/31/21` - `01/31/20`) / `01/31/20`) * 100
  ) %>%
  ungroup() %>% drop_na() %>%
  slice_min(price_drop, n = 10) %>%
  select(zip_code, borough, neighborhood, jan_2020 = `01/31/20`, jan_2021 = `01/31/21`, price_drop, percent_drop) %>%
  mutate(across(where(is.numeric), round, 2))
kable(top_drops)
```
The ten neighborhoods with the  largest drop in price from January 2020 to 2021 are:














